{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Medicine\n",
    "## BMSC-GA 4493, BMIN-GA 3007 \n",
    "## Lab 1: PyTorch Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of this lab: \n",
    "   - Understand Pytorch Tensor and its operation\n",
    "   - Understand AutoGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tensor\n",
    "   1. Multi-dimensional Arrays\n",
    "   2. Data Types\n",
    "        - torch.FloatTensor\n",
    "        - torch.IntTensor\n",
    "   3. Compatible with Numpy Array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Pytorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(6, 2)  # construct a 6x2 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(6, 2)  # construct a randomly initialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.ones(7) # construct a matrix of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, z.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a 3D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = torch.rand(3, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tensor of specific type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_tensor, float_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an integer tensor\n",
    "int_tensor = torch.tensor([1, 2, 3], dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_tensor, int_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean tensor\n",
    "bool_tensor = torch.tensor([True, False, True], dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_tensor, bool_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert between types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float32\n",
    "float_tensor = int_tensor.float()\n",
    "float_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to int64\n",
    "int_tensor = float_tensor.to(torch.int64)\n",
    "int_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to boolean\n",
    "bool_tensor = int_tensor.bool()\n",
    "bool_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion between Tensor array and Numpy array\n",
    "    - They share the same memory location! So one change will affect another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch tensor\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# Convert the tensor to a NumPy array\n",
    "array = tensor.numpy()\n",
    "\n",
    "# Show the initial values of the tensor and array\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"Original array:\", array)\n",
    "print()\n",
    "# Modify the tensor\n",
    "tensor[0] = 10\n",
    "\n",
    "# Show the modified tensor and array\n",
    "print(\"Modified tensor:\", tensor)\n",
    "print(\"Modified array:\", array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a NumPy array\n",
    "array = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Convert the NumPy array to a PyTorch tensor\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "# Show the initial values of the array and tensor\n",
    "print(\"Original array:\", array)\n",
    "print(\"Original tensor:\", tensor)\n",
    "\n",
    "# Modify the array\n",
    "array[0] = 10\n",
    "\n",
    "# Show the modified array and tensor\n",
    "print(\"Modified array:\", array)\n",
    "print(\"Modified tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operation Examples\n",
    "Related reading and reference:\n",
    "    \n",
    "* PyTorch documentation:\n",
    "<a href=\"https://pytorch.org/docs/stable/nn.html\"> https://pytorch.org/docs/stable/nn.html </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two 2D tensors (matrices)\n",
    "matrix1 = torch.tensor([[1, 2],\n",
    "                        [3, 4]])\n",
    "matrix2 = torch.tensor([[5, 6], \n",
    "                        [7, 8]])\n",
    "\n",
    "# Matrix Addition\n",
    "add_result = matrix1 + matrix2\n",
    "print(\"Matrix Addition:\\n\", add_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Subtraction\n",
    "subtract_result = matrix1 - matrix2\n",
    "print(\"Matrix Subtraction:\\n\", subtract_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise Multiplication\n",
    "elementwise_multiply_result = matrix1 * matrix2\n",
    "print(\"Element-wise Multiplication:\\n\", elementwise_multiply_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Multiplication (Dot Product)\n",
    "# Using matmul for dot product of matrices\n",
    "dot_product_result = matrix1 @ matrix2\n",
    "print(\"Matrix Multiplication (Dot Product):\\n\", dot_product_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd: automatic differentiation\n",
    "* Autograd is an automatic differentiation system in PyTorch. It's a key component for training neural networks. Autograd records operations on tensors as they are performed. When the computation is complete, you can call **.backward()** on the final output tensor to efficiently compute gradients (partial derivatives) of all involved tensors that have **requires_grad=True**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regarding the function $L$:\n",
    "$L = (y_{\\text{pred}} - y_{\\text{true}})^2 \\\\ \n",
    "y = Wx + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradients for variables $W$ and $b$ are:\n",
    "$\\frac{\\partial L}{\\partial W} = 2x(y_{\\text{pred}} - y_{\\text{true}}) \\\\$\n",
    "$\\frac{\\partial L}{\\partial b} = 2(y_{\\text{pred}} - y_{\\text{true}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (x), Parameters (W, b), and Target (y_true)\n",
    "x = torch.tensor([1.0], requires_grad=False)  # Input\n",
    "W = torch.tensor([2.0], requires_grad=True)  # Weight\n",
    "b = torch.tensor([1.0], requires_grad=True)  # Bias\n",
    "y_true = torch.tensor([5.0])  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Model: y_pred = W*x + b\n",
    "y_pred = W * x + b\n",
    "\n",
    "# Loss Function: Mean Squared Error\n",
    "loss = (y_pred - y_true) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients of W and b\n",
    "W_grad = W.grad\n",
    "b_grad = b.grad\n",
    "\n",
    "print(\"Gradient of W:\", W_grad.item())\n",
    "print(\"Gradient of b:\", b_grad.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the computed gradient to minimize the loss funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "def mse_loss(y_pred, y_true):\n",
    "    return ((y_pred - y_true) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input, target, and initial weight\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=False)\n",
    "y = torch.tensor([5.0, 4.0, 1.0], requires_grad=False)\n",
    "W = torch.rand((3,),requires_grad=True)\n",
    "\n",
    "# Initialization\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "loss_values = []  # List to store loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass: Compute predicted y\n",
    "    y_pred = W * x\n",
    "\n",
    "    # Compute loss\n",
    "    loss = mse_loss(y_pred, y)\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    # Zero gradients before backward pass\n",
    "    W.grad = None\n",
    "\n",
    "    # Backward pass to compute gradient of loss with respect to W\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad\n",
    "\n",
    "# Plotting the loss over epochs\n",
    "plt.plot(loss_values, label='Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                                    Simple Neural Network Update\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.researchgate.net/publication/329777725/figure/fig2/AS:705569090465794@1545232188535/A-simple-neural-network-diagram-with-one-hidden-layer.ppm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and Outpute\n",
    "n_samples, input_size, hidden_size, output_size = 64, 3, 4, 2\n",
    "X = torch.randn(n_samples, input_size)  # Example input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = torch.tensor([[0,1]], dtype = torch.int64)\n",
    "for i in range(0,31):\n",
    "    y1 = torch.concatenate((y1,torch.tensor([[0,1]], dtype = torch.int64)), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = torch.tensor([[1,0]], dtype = torch.int64)\n",
    "for i in range(0,31):\n",
    "    y1 = torch.concatenate((y1,torch.tensor([[1,0]], dtype = torch.int64)), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.concatenate((y1,y2), axis = 0)\n",
    "Y.dtype\n",
    "Y = Y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.size(), Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight matrices\n",
    "W1 = torch.randn(input_size, hidden_size, requires_grad=True)  # Input to Hidden\n",
    "W2 = torch.randn(hidden_size, output_size, requires_grad=True)  # Hidden to Output\n",
    "\n",
    "# Training loop\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "loss_values = []  # To track loss values\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    hidden = F.relu(X @ W1)  # Activation function for hidden layer\n",
    "    output = hidden @ W2     # No activation function, raw scores\n",
    "\n",
    "    # Loss calculation\n",
    "    loss = F.mse_loss(output, Y)\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    # Backward pass (computing gradients)\n",
    "    loss.backward()\n",
    "\n",
    "    # Updating weights with gradients\n",
    "    with torch.no_grad():\n",
    "        W1 -= learning_rate * W1.grad\n",
    "        W2 -= learning_rate * W2.grad\n",
    "\n",
    "        # Zero gradients after updating\n",
    "        W1.grad.zero_()\n",
    "        W2.grad.zero_()\n",
    "\n",
    "    # Display weights and loss occasionally\n",
    "    if epoch % 25 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "        print('Weights of First Layer (W1):', W1)\n",
    "        print('Weights of Second Layer (W2):', W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_values, label='Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
